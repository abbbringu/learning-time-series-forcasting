{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Template\n",
    "\n",
    "This notebook provides a template for time series forecasting experiments.\n",
    "\n",
    "## Steps:\n",
    "1. Load and explore data\n",
    "2. Preprocess and create features\n",
    "3. Split into train/test sets\n",
    "4. Build and train models\n",
    "5. Evaluate and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom utilities\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from utils import (\n",
    "    load_csv_timeseries,\n",
    "    train_test_split_timeseries,\n",
    "    create_lag_features,\n",
    "    create_rolling_features,\n",
    "    plot_timeseries,\n",
    "    plot_forecast,\n",
    "    plot_decomposition,\n",
    "    evaluate_forecast,\n",
    "    print_metrics\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "# df = load_csv_timeseries(\n",
    "#     filepath='../data/raw/your_data.csv',\n",
    "#     date_column='date',\n",
    "#     target_column='value',\n",
    "#     freq='D'  # Daily frequency\n",
    "# )\n",
    "\n",
    "# For demo purposes, create sample data\n",
    "dates = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
    "trend = np.linspace(100, 200, len(dates))\n",
    "seasonal = 20 * np.sin(2 * np.pi * np.arange(len(dates)) / 365.25)\n",
    "noise = np.random.normal(0, 5, len(dates))\n",
    "values = trend + seasonal + noise\n",
    "\n",
    "df = pd.DataFrame({'value': values}, index=dates)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(df.describe())\n",
    "print(f\"\\nData shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the time series\n",
    "plot_timeseries(df, title='Time Series Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decomposition\n",
    "plot_decomposition(df['value'], model='additive', period=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# If there are missing values, handle them\n",
    "# df = fill_missing_values(df, method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (80% train, 20% test)\n",
    "train, test = train_test_split_timeseries(df, test_size=0.2)\n",
    "\n",
    "print(f\"Train size: {len(train)}\")\n",
    "print(f\"Test size: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building\n",
    "\n",
    "### 4.1 Statistical Model (ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit ARIMA model\n",
    "model_arima = ARIMA(train['value'], order=(1, 1, 1))\n",
    "fitted_arima = model_arima.fit()\n",
    "\n",
    "# Make predictions\n",
    "forecast_arima = fitted_arima.forecast(steps=len(test))\n",
    "forecast_arima.index = test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Prophet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "\n",
    "# Prepare data for Prophet (requires 'ds' and 'y' columns)\n",
    "train_prophet = train.reset_index()\n",
    "train_prophet.columns = ['ds', 'y']\n",
    "\n",
    "# Fit Prophet model\n",
    "model_prophet = Prophet()\n",
    "model_prophet.fit(train_prophet)\n",
    "\n",
    "# Make predictions\n",
    "future = model_prophet.make_future_dataframe(periods=len(test))\n",
    "forecast_prophet_df = model_prophet.predict(future)\n",
    "forecast_prophet = forecast_prophet_df['yhat'].iloc[-len(test):]\n",
    "forecast_prophet.index = test.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Machine Learning Model (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Create features\n",
    "train_ml = create_lag_features(train, 'value', lags=[1, 7, 14, 30])\n",
    "train_ml = create_rolling_features(train_ml, 'value', windows=[7, 30])\n",
    "train_ml = train_ml.dropna()\n",
    "\n",
    "# Prepare train data\n",
    "X_train = train_ml.drop('value', axis=1)\n",
    "y_train = train_ml['value']\n",
    "\n",
    "# Fit XGBoost model\n",
    "model_xgb = XGBRegressor(n_estimators=100, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Prepare test data with same features\n",
    "full_data = pd.concat([train, test])\n",
    "test_ml = create_lag_features(full_data, 'value', lags=[1, 7, 14, 30])\n",
    "test_ml = create_rolling_features(test_ml, 'value', windows=[7, 30])\n",
    "test_ml = test_ml.loc[test.index]\n",
    "\n",
    "X_test = test_ml.drop('value', axis=1)\n",
    "forecast_xgb = pd.Series(model_xgb.predict(X_test), index=test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ARIMA\n",
    "print(\"ARIMA Model:\")\n",
    "metrics_arima = evaluate_forecast(test['value'].values, forecast_arima.values, train['value'].values)\n",
    "print_metrics(metrics_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Prophet\n",
    "print(\"Prophet Model:\")\n",
    "metrics_prophet = evaluate_forecast(test['value'].values, forecast_prophet.values, train['value'].values)\n",
    "print_metrics(metrics_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost\n",
    "print(\"XGBoost Model:\")\n",
    "metrics_xgb = evaluate_forecast(test['value'].values, forecast_xgb.values, train['value'].values)\n",
    "print_metrics(metrics_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models visually\n",
    "from utils import plot_multiple_forecasts\n",
    "\n",
    "forecasts = {\n",
    "    'ARIMA': forecast_arima,\n",
    "    'Prophet': forecast_prophet,\n",
    "    'XGBoost': forecast_xgb\n",
    "}\n",
    "\n",
    "plot_multiple_forecasts(\n",
    "    actual=test['value'],\n",
    "    forecasts=forecasts,\n",
    "    train=train['value'].iloc[-100:],  # Show last 100 days of training\n",
    "    title='Model Comparison'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics in a table\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'ARIMA': metrics_arima,\n",
    "    'Prophet': metrics_prophet,\n",
    "    'XGBoost': metrics_xgb\n",
    "})\n",
    "\n",
    "print(\"\\nMetrics Comparison:\")\n",
    "print(metrics_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "- Summarize which model performed best\n",
    "- Note any patterns or insights\n",
    "- Suggest next steps for improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
